## Question: Real-Time Traffic Incident Aggregation and Analysis

**Problem Description:**

You are tasked with building a system to aggregate and analyze real-time traffic incident data from multiple unreliable and heterogeneous data streams. These streams provide information about traffic incidents such as accidents, road closures, and congestion. Your goal is to identify and report significant traffic events that impact a large area, while minimizing false positives and ensuring timely updates.

**Input:**

The system receives a continuous stream of incident reports from multiple sources. Each report contains the following information:

*   `incident_id`: A unique identifier for the incident (string).
*   `incident_type`: The type of incident (e.g., "accident", "road_closure", "congestion") (string).
*   `location`: Geographic coordinates (latitude, longitude) represented as floats.
*   `timestamp`: The time the incident was reported (Unix timestamp - integer).
*   `severity`: A subjective measure of the incident's severity (integer from 1 to 5, where 5 is the most severe).
*   `source`: An identifier for the data source (string).
*   `confidence`: A value representing the reliability of the data source (float from 0.0 to 1.0).

**Output:**

The system should identify and report significant traffic *events*. An event is defined as a cluster of related incidents occurring within a specific geographical area and time window. The system should output a list of significant events, each containing:

*   `event_id`: A unique identifier for the event (generated by your system).
*   `event_type`: The most frequent incident type within the event cluster.
*   `location`: The centroid (average latitude and longitude) of the incident cluster.
*   `start_time`: The earliest timestamp of an incident within the event cluster.
*   `end_time`: The latest timestamp of an incident within the event cluster.
*   `severity`: The average severity of incidents within the event cluster, weighted by the confidence of their respective sources.
*   `incident_ids`: A list of `incident_id` values included in the event.

**Constraints and Requirements:**

1.  **Real-time Processing:** The system must process incident reports with minimal latency.  The goal is to detect and report events within a few seconds of the incidents being reported.
2.  **Unreliable Data Sources:** The data sources are unreliable, and reports may be inaccurate, duplicated, or delayed.  The system must be robust to noisy data and ensure high accuracy in event detection.
3.  **Heterogeneous Data Sources:** Data sources may have varying levels of accuracy and reporting frequency.  The system must handle this heterogeneity effectively.
4.  **Scalability:** The system should be able to handle a large volume of incident reports from numerous sources.
5.  **Event Definition Parameters:** The following parameters must be configurable:
    *   `radius`: The maximum geographical distance (in kilometers) between incidents to be considered part of the same event.
    *   `time_window`: The maximum time difference (in seconds) between incidents to be considered part of the same event.
    *   `min_incidents`: The minimum number of incidents required to form a significant event.
    *   `confidence_threshold`: The minimum average weighted confidence score an event must have to be considered significant.
6.  **Optimization:** Minimize memory usage and computational complexity. Naive algorithms may time out or consume excessive resources. Focus on efficiency for real-time processing.
7.  **Edge Cases:** Handle edge cases such as:
    *   Empty input streams.
    *   Incidents with missing or invalid data.
    *   Overlapping events.
8.  **Geographical Considerations:** You can assume a flat Earth model for distance calculations within the specified radius. The Haversine formula or similar can be used for more accurate calculations if desired, but simplicity is preferred unless performance is demonstrably impacted.

**Judging Criteria:**

*   **Correctness:** The accuracy of event detection and the correctness of event attributes (location, time, severity, etc.).
*   **Efficiency:** The speed of event detection and the memory usage of the system.
*   **Scalability:** The ability of the system to handle a large volume of incident reports.
*   **Robustness:** The ability of the system to handle noisy and unreliable data.
*   **Code Quality:** The clarity, readability, and maintainability of the code.
*   **Adherence to Constraints:** Meeting all the specified constraints and requirements.
*   **Algorithm Sophistication**: The intelligent use of data structures and algorithms to solve the problem efficiently and effectively.

This problem requires a combination of algorithmic thinking, data structure design, and system design considerations. Good luck!
